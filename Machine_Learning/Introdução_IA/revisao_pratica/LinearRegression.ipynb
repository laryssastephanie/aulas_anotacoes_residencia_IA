{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exemplo Regress√£o Linear\n",
    "\n",
    "Dado um conjunto de pontos, a ideia √© encontrar uma reta que melhor represente o comportamento desses dados.\n",
    "Ap√≥s encontrar essa reta, √© poss√≠vel predizer a sa√≠da de uma nova amostra cujo valor √© desconhecido.\n",
    "\n",
    "\n",
    "![alt tag](assets/img1.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Regress√£o Linear** √© um modelo b√°sico de predi√ß√£o que usa dados hist√≥ricos para predizer a sa√≠da de uma vari√°vel. √â muito popular para modelos de predi√ß√£o por ser f√°cil de entender e implementar.\n",
    "\n",
    "Modelos de regress√£o linear tem muitas aplica√ß√µes em problemas reais, como economia, ci√™ncias sociais, sa√∫de, etc.\n",
    "\n",
    "Entender como implementar um modelo de regress√£o linear pode desenterrar o hist√≥rico dos dados para resolver problemas presentes e futuros. Usaremos Python por ser uma ferramenta robusta para lidar, processar e modelar dados. Al√©m disso, cont√©m uma quantidade muito grande de bibliotecas para aprendizagem de m√°quinas e modelagem de dados.\n",
    "\n",
    "A ideia b√°sica da regress√£o linear √© encontrar uma reta que represente o conjunto de dados observados (conjunto de treinamento). O modelo pode ent√£o ser usado para predizer valores futuros. Vamos assumir, por exemplo, que descobrimos nesses dados hist√≥ricos que o pre√ßo (P) de uma case √© linearmente dependente do seu tamanho (S) - na verdade, n√≥s descobrimos que o pre√ßo das casas √© exatamente 90 vezes o seu tamanho. A equa√ß√£o √© definida a seguir:\n",
    "\n",
    "\\begin{equation}\n",
    "P = 90*S\n",
    "\\end{equation}\n",
    "\n",
    "Com esse modelo, n√≥s podemos predizer o custo de qualquer casa. Se tivermos uma casa que com $1,500$ metros quadrados, podemos calcular seu pre√ßo como sendo:\n",
    "\n",
    "\\begin{equation}\n",
    "P = 90*1500 = \\$135,000\n",
    "\\end{equation}\n",
    "\n",
    "Nessa aula, vamos aprender:\n",
    "\n",
    "\n",
    "1. os conceitos b√°sicos e matem√°ticos por tr√°s do modelo\n",
    "2. como implementar regress√£o linear do princ√≠pio (solu√ß√£o anal√≠tica)\n",
    "3. como implementar regress√£o linear usando scikit-learn\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conceitos b√°sicos e matem√°ticos\n",
    "\n",
    "Existem dois tipos de vari√°veis em um modelo de regress√£o linear:\n",
    "\n",
    "- valores de **entrada**, que ajudam a predizer a vari√°vel de sa√≠da. Comumente, √© chamada de $X$.\n",
    "- a vari√°vel de **sa√≠da**, que √© o valor que desejamos descobrir. Em geral, √© chamada de $y$.\n",
    "\n",
    "Para estimar $y$ usando regress√£o linear, n√≥s usamos a equa√ß√£o:\n",
    "\n",
    "\\begin{equation}\n",
    "y_e = \\alpha + \\beta X\n",
    "\\end{equation}\n",
    "onde $y_e$ √© o valor estimado de $y$ baseado na equa√ß√£o linear. Note que a equa√ß√£o √© identica √† equa√ß√£o da reta, sendo que $\\beta$ define a inclina√ß√£o da reta e $\\alpha$ representa a altura que essa linha corta o eixo $y$ quando o valor no eixo $x$ √© igual a zero.\n",
    "\n",
    "Nosso objetivo √© encontrar os valores dos par√¢metros $\\alpha$ e $\\beta$ que minimizem a difer√™n√ßa entre $y$ e $y_e$.\n",
    "\n",
    "Se pudermos determinar o valor √≥timo desses dois par√¢metros, ent√£o teremos a linha que melhor se ajusta aos dados para predizer o valor de $y$, dado o valor de $X$.\n",
    "\n",
    "Ent√£o, como podemos estimar $\\alpha$ e $\\beta$? Podemos usar o m√©todo dos m√≠nimos quadrados (ordinary least squares).\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### M√©todo dos m√≠nimos quadrados\n",
    "\n",
    "![alt tag](assets/ols.png)\n",
    "\n",
    "O objetivo do m√©todo dos m√≠nimos quadrados √© encontrar valores de $\\alpha$ e $\\beta$ que minimizam a soma da diferen√ßa ao quadrado entre $y$ e $y_e$. Usando calculo, podemos encontrar esses valores da seguinte maneira:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\beta = \\frac{\\sum_{i=1}^n(X_i-\\hat{X})(y_i-\\hat{y})}{\\sum_{i=1}^n(X_i-\\hat{X})^2}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\alpha = \\hat{y}-\\beta * \\hat{X}\n",
    "\\end{equation}\n",
    "onde $\\hat{X}$ e $\\hat{y}$ representam os valores m√©dios das vari√°veis $X$ e $Y$, respectivamente, e $n$ representa o n√∫mero de amostras."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementa√ß√£o 'na m√£o' (solu√ß√£o anal√≠tica)\n",
    "\n",
    "Antes de mergulharmos nas implementa√ß√µes pr√°ticas usando bibliotecas como o scikit-learn, √© interessante entender como implementar o modelo desde o in√≠cio.\n",
    "\n",
    "Para come√ßar, vamos simular alguns dados e verificar como os valores preditos ($y_e$) diferencial do valor real de sa√≠da ($y$)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd # biblioteca para importar e manusear dados.\n",
    "import numpy as np # biblioteca com fun√ß√µes para lidar com arrays, express√µes matem√°ticas, dentre outros.\n",
    "from matplotlib import pyplot as plt # biblioteca para plotar dados.\n",
    "\n",
    "# Gerando dados aleat√≥rios\n",
    "np.random.seed(0)\n",
    "X = 2.5 * np.random.randn(100) + 1.5   # Array com 100 valores com m√©dia 1.5 e desvio = 2.5\n",
    "res = 0.5 * np.random.randn(100)       # gerando 100 termos residuais\n",
    "y = 2 + 0.3 * X + res                  # valores reais de y\n",
    "\n",
    "# Criando uma dataframe Pandas para armazenar nossos valores de X e y.\n",
    "df = pd.DataFrame(\n",
    "    {'X': X,\n",
    "     'y': y}\n",
    ")\n",
    "\n",
    "# mostrando as primeiras 5 linhas do nosso dataframe.\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          X         y\n",
       "0  5.910131  4.714615\n",
       "1  2.500393  2.076238\n",
       "2  3.946845  2.548811\n",
       "3  7.102233  4.615368\n",
       "4  6.168895  3.264107"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.910131</td>\n",
       "      <td>4.714615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.500393</td>\n",
       "      <td>2.076238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.946845</td>\n",
       "      <td>2.548811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.102233</td>\n",
       "      <td>4.615368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.168895</td>\n",
       "      <td>3.264107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Antes de estimar os valores de $\\alpha$ e $\\beta$, precisamos computar os valores m√©dio de $X$ e $y$, i.e., $xmean$ e $ymean$, a covariancia de $X$ e $y$ ($xycov$), e a variancia de $X$ ($xvar$)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Calculando as m√©dias de X e y.\n",
    "xmean = np.mean(X)\n",
    "ymean = np.mean(y)\n",
    "\n",
    "# Calcular os termos necess√°rios para encontrar ùõΩ, \n",
    "# i.e., o numerador (covariancia entre X e y) e o denominador (vari√¢ncia de X).\n",
    "df['xycov'] = (df['X'] - xmean) * (df['y'] - ymean)\n",
    "df['xvar'] = (df['X'] - xmean)**2\n",
    "\n",
    "# Computando ùõΩ e ùõº.\n",
    "beta = df['xycov'].sum() / df['xvar'].sum()\n",
    "alpha = ymean - (beta * xmean)\n",
    "print(f'alpha = {alpha}')\n",
    "print(f'beta = {beta}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "alpha = 2.0031670124623426\n",
      "beta = 0.3229396867092763\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora que encontramos os valores de $\\alpha$ e $\\beta$, nosso modelo pode ser escrito da como $y_e = 2.003 + 0.323 * X$, e podemos fazer predi√ß√µes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "ypred = alpha + beta * X\n",
    "print(ypred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3.91178282 2.81064315 3.27775989 4.29675991 3.99534802 1.69857201\n",
      " 3.25462968 2.36537842 2.40424288 2.81907292 2.60387001 3.66168312\n",
      " 3.10199975 2.58581077 2.84592918 2.75696825 3.69382011 2.32194218\n",
      " 2.74033151 1.79802302 0.42642221 3.015275   3.18547843 1.88839019\n",
      " 4.32006116 1.31339555 2.52451965 2.33645381 3.72506464 3.67386219\n",
      " 2.61267323 2.79288576 1.77082341 0.88838207 2.20668994 2.61380476\n",
      " 3.48085076 3.45831697 2.17486854 2.24351265 1.64102813 1.34112617\n",
      " 1.11002064 4.06253353 2.07610925 2.1338976  1.47613319 3.11528277\n",
      " 1.18459738 2.31582084 1.76462232 2.79994197 2.07517841 1.53439407\n",
      " 2.46482364 2.83338994 2.54127917 2.73177699 1.9754571  2.19471775\n",
      " 1.94466613 2.19729158 1.83108353 1.09386364 2.6308214  2.16319902\n",
      " 1.17143718 2.86120343 1.75506992 2.52951462 3.07620724 2.59171079\n",
      " 3.40747079 1.49064088 2.81240675 1.93469565 1.78453915 2.02024272\n",
      " 2.23604485 2.53292159 1.54689373 3.2148581  2.86352875 1.24729141\n",
      " 3.68911579 4.01822118 3.43926331 2.34231437 1.62310525 3.33888732\n",
      " 2.16207195 3.47451661 2.65572718 3.2760653  2.77528867 3.05802784\n",
      " 2.49605373 3.92939769 2.59003892 2.81212234]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos plotar a predi√ß√£o $ypred$ contra o valor real de $y$, providenciando uma compreens√£o visual de nosso modelo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Plotando a regress√£o contra os dados reais\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(X, ypred)     # linha da regress√£o\n",
    "plt.plot(X, y, 'ro')   # scatter plot mostrando os dados reais\n",
    "plt.title('Real vs Predito')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A linha azul √© o melhor ajuste √† equa√ß√£o $y_e = 2.003 + 0.323 X$. Podemos observar no gr√°fico que existe uma rela√ß√£o linear positiva entre $X$ e $y$. Usando nosso modelo, podemos predizer $y$ a partir de qualquer valor de $X$.\n",
    "\n",
    "Ex: $y_e = 2.003 + 0.323 (10) = 5.233$.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regress√£o Linear usando scikit-learn\n",
    "\n",
    "Agora que sabemos como implementar o regressor linear ''na m√£o'', vamos aprender a usar o scikit-learn para predizer um valor de sa√≠da utilizando vari√°veis de entrada com duas (ou mais) dimens√µes. Para isso, utilizaremos um famoso dataset chamado *advertising*, o qual √© composto pelos custos incorridos em propagandas utilizando diversos meios e as vendas de um produto particular.\n",
    "\n",
    "Neste exemplo, observaremos como as vari√°veis TV e R√°dio podem predizer o n√∫mero de vendas de um determinado produto. Vamos come√ßar importando o dataset no formato csv como um Pandas dataframe usando a fun√ß√£o read_csv(): "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Importa e mostra as cinco primeiras linhas do dataset advertising.\n",
    "\n",
    "# pode ser baixado em: https://www.kaggle.com/purbar/advertising-data#Advertising.csv\n",
    "\n",
    "advert = pd.read_csv('data/Advertising.csv')\n",
    "advert.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0     TV  Radio  Newspaper  Sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Um regressor linear com mais de uma vari√°vel de predi√ß√£o √© modelado da seguinte forma:\n",
    "\n",
    "\\begin{equation}\n",
    "    y_e = \\alpha + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p,\n",
    "\\end{equation}\n",
    "onde $p$ √© o n√∫mero de vari√°veis de predi√ß√£o.\n",
    "\n",
    "No nosso exemplo, iremos predizer o n√∫mero de produtos vendidos (Sales) usando as vari√°veis TV e R√°dio, i.e., nosso modelo pode ser escrito como:\n",
    "\n",
    "\\begin{equation}\n",
    "    Vendas = \\alpha + \\beta_1TV + \\beta_2Radio.\n",
    "\\end{equation}\n",
    "\n",
    "Primeiramente, vamos inicializar nosso modelo de regress√£o linear, e ent√£o ajustar o modelo √†s nossas vari√°veis de predi√ß√£o e valor de sa√≠da:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Constroi o modelo de regress√£o linear usando as vari√°veis TV e Radio.\n",
    "# Separa os dados em vari√°veis de predi√ß√£o de entrada X e a sa√≠da y\n",
    "predictors = ['TV', 'Radio']\n",
    "X = advert[predictors]\n",
    "y = advert['Sales']\n",
    "\n",
    "# Inicializa e ajusta o modelo\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dessa vez n√£o √© necess√°rio calcular os valores de $\\alpha$ e os $\\beta$s, uma que nosso modelo retorna esses valores atrav√©s das chamadas .intercept_ para o $\\alpha$ e .coef_ para retornar o array com os valores de $\\beta_1$ e $\\beta_2$:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "alpha = model.intercept_\n",
    "betas = model.coef_\n",
    "\n",
    "print(f'alpha = {alpha}')\n",
    "print(f'betas = {betas}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "alpha = 2.921099912405138\n",
      "betas = [0.04575482 0.18799423]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sendo assim, nosso modelo pode ser escrito como:\n",
    "\n",
    "\\begin{equation}\n",
    "    Vendas = 2.921 + 0.046 * TV + 0.188 * Radio.\n",
    "\\end{equation}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "beta1 = betas[0]\n",
    "beta2 = betas[1]\n",
    "TV = advert['TV']\n",
    "Radio = advert['Radio']\n",
    "\n",
    "vendas = alpha + beta1 * TV + beta2 * Radio\n",
    "print(f'vendas = {vendas.values}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vendas = [20.55546463 12.34536229 12.33701773 17.61711596 13.22390813 12.51208449\n",
      " 11.71821241 12.10551553  3.7093792  12.55169696  7.0358597  17.25652015\n",
      " 10.60866187  8.81095051 18.44466773 20.82891539 12.90386507 23.24107626\n",
      "  9.94121476 14.15384619 18.12139161 14.74206357  6.51417168 16.54402663\n",
      "  8.14035215 15.6080206  14.96769383 17.0463346  19.39954145  9.15929748\n",
      " 21.64292187 11.35791808  7.65045928 18.83346334  7.56302763 16.99280099\n",
      " 23.36720719 15.6258994   9.91257829 20.4405801  16.37872122 17.29870935\n",
      " 21.5621537  13.96692266  8.9009974  15.16263814  8.88644967 21.69944046\n",
      " 16.28690268  8.18162949 12.64569407  9.31962792 20.66180115 19.96126242\n",
      " 20.35512357 21.30864743  8.53774783 12.76239488 21.89072858 18.10746914\n",
      "  5.74497097 22.90418658 16.78413768 13.18474853 16.96570907  7.82652846\n",
      "  8.98703456 12.02066194 18.95313425 21.09369037 17.78350693 10.63329605\n",
      " 10.35113844  9.91334008 17.30983543 11.90970399  4.48014809 13.79239059\n",
      "  8.78920329  9.67621401 11.43621364 14.6638809  10.18272029 14.41647235\n",
      " 20.77350468 15.22002396 11.58203354 15.61872354 11.75510286 16.93110264\n",
      "  9.98714329  4.51167896 19.17972975 21.26277229 10.46708623 16.33347878\n",
      " 12.62023117 15.32904398 24.12842563 16.94651016 13.90534597 23.30701753\n",
      " 17.64034079 14.75193037 20.26809884 17.95362103  6.13290678  7.11373347\n",
      "  3.59568568 19.66392439 14.79408982 21.12381933 13.85533202 16.38399023\n",
      " 15.29725626 12.93708446 11.97848762  6.56716317 15.60946713  6.81665095\n",
      " 14.42450056  7.86076515 13.62136464 15.05811789 19.4940435   9.12925166\n",
      " 10.59096289  6.59063608 22.21260278  7.90401761 10.39769966 15.60046013\n",
      "  8.41888332 19.27581486 11.86602974 13.96678613 11.42419802 20.87722595\n",
      "  9.75760743 19.63411177  9.47540519 18.43880322 19.25144497  8.77862066\n",
      " 10.10502768  9.6976895  15.27918887 23.26038805 12.23595022  9.81659119\n",
      " 18.37759626 10.03658404 16.34251686 18.22227054 15.48053237  5.28942768\n",
      " 15.39522591 10.01956371 10.39341821 12.40610283 14.21650102 13.57248088\n",
      " 14.94400258 17.32019972 11.04707937 14.28978442 10.80869402 13.36076565\n",
      " 17.21335083 17.92193265  7.3895737  14.37684633  7.59657824 11.96096978\n",
      " 13.73615116 24.7835259  19.96402163 12.17492441 16.01384397 12.37803956\n",
      " 10.57508895 13.93369584  6.56408761 24.16393648 18.53794901 20.77937663\n",
      "  9.69868449 17.06027938 18.62009678  6.0514451  12.45497782  8.4059261\n",
      "  4.47885906 18.44876059 16.4631902   5.36451249  8.15237521 12.76804849\n",
      " 23.79292299 15.15754285]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por√©m, uma op√ß√£o melhor √© simplesmente usar a fun√ß√£o .predict():"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "vendas = model.predict(X)\n",
    "print(f'vendas = {vendas}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vendas = [20.55546463 12.34536229 12.33701773 17.61711596 13.22390813 12.51208449\n",
      " 11.71821241 12.10551553  3.7093792  12.55169696  7.0358597  17.25652015\n",
      " 10.60866187  8.81095051 18.44466773 20.82891539 12.90386507 23.24107626\n",
      "  9.94121476 14.15384619 18.12139161 14.74206357  6.51417168 16.54402663\n",
      "  8.14035215 15.6080206  14.96769383 17.0463346  19.39954145  9.15929748\n",
      " 21.64292187 11.35791808  7.65045928 18.83346334  7.56302763 16.99280099\n",
      " 23.36720719 15.6258994   9.91257829 20.4405801  16.37872122 17.29870935\n",
      " 21.5621537  13.96692266  8.9009974  15.16263814  8.88644967 21.69944046\n",
      " 16.28690268  8.18162949 12.64569407  9.31962792 20.66180115 19.96126242\n",
      " 20.35512357 21.30864743  8.53774783 12.76239488 21.89072858 18.10746914\n",
      "  5.74497097 22.90418658 16.78413768 13.18474853 16.96570907  7.82652846\n",
      "  8.98703456 12.02066194 18.95313425 21.09369037 17.78350693 10.63329605\n",
      " 10.35113844  9.91334008 17.30983543 11.90970399  4.48014809 13.79239059\n",
      "  8.78920329  9.67621401 11.43621364 14.6638809  10.18272029 14.41647235\n",
      " 20.77350468 15.22002396 11.58203354 15.61872354 11.75510286 16.93110264\n",
      "  9.98714329  4.51167896 19.17972975 21.26277229 10.46708623 16.33347878\n",
      " 12.62023117 15.32904398 24.12842563 16.94651016 13.90534597 23.30701753\n",
      " 17.64034079 14.75193037 20.26809884 17.95362103  6.13290678  7.11373347\n",
      "  3.59568568 19.66392439 14.79408982 21.12381933 13.85533202 16.38399023\n",
      " 15.29725626 12.93708446 11.97848762  6.56716317 15.60946713  6.81665095\n",
      " 14.42450056  7.86076515 13.62136464 15.05811789 19.4940435   9.12925166\n",
      " 10.59096289  6.59063608 22.21260278  7.90401761 10.39769966 15.60046013\n",
      "  8.41888332 19.27581486 11.86602974 13.96678613 11.42419802 20.87722595\n",
      "  9.75760743 19.63411177  9.47540519 18.43880322 19.25144497  8.77862066\n",
      " 10.10502768  9.6976895  15.27918887 23.26038805 12.23595022  9.81659119\n",
      " 18.37759626 10.03658404 16.34251686 18.22227054 15.48053237  5.28942768\n",
      " 15.39522591 10.01956371 10.39341821 12.40610283 14.21650102 13.57248088\n",
      " 14.94400258 17.32019972 11.04707937 14.28978442 10.80869402 13.36076565\n",
      " 17.21335083 17.92193265  7.3895737  14.37684633  7.59657824 11.96096978\n",
      " 13.73615116 24.7835259  19.96402163 12.17492441 16.01384397 12.37803956\n",
      " 10.57508895 13.93369584  6.56408761 24.16393648 18.53794901 20.77937663\n",
      "  9.69868449 17.06027938 18.62009678  6.0514451  12.45497782  8.4059261\n",
      "  4.47885906 18.44876059 16.4631902   5.36451249  8.15237521 12.76804849\n",
      " 23.79292299 15.15754285]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora que ajustamos um regressor linear com multiplas variaveis de entradas, podemos predizer a quantidade de vendas para qualquer combina√ß√£o de valor gasto com propagando em TV e R√°dio! Por exemplo, se quisermos saber quantas vendas fariamos ao investir $\\$300$ em propaganda na TV e $\\$200$ em propaganda em r√°dios, a √∫nica coisa a fazer √© plugar esses novos valores:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "new_X = [[300, 200]]\n",
    "print(model.predict(new_X))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[54.24638977]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Isso significa que se gastarmos $\\$300$ em propaganda na TV e $\\$200$ em propaganda em r√°dios, poderiamos esperar, em m√©dia, vender 54 unidades de nosso produto."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nessa aula, n√≥s implementamos um modelo de regress√£o linear em python ''na m√£o'' e usando scikit-learn. Espero que tenham gostado."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exerc√≠cios\n",
    "\n",
    "1. Ajustar o modelo ''Na m√£o'' utilizando o dataset *Advertising* para, dado o valor gasto com propaganda na TV, predizer a quantidade de produtos vendidos.\n",
    "\n",
    "2. Ajustar o modelo utilizando scikit-learn para predizer a quantidade de produtos vendidos considerando os gastos em propaganda na TV, R√°dio e Jornal (newspaper)."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}